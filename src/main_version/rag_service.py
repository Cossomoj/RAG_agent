import os
from dotenv import load_dotenv
import string
import asyncio
import sqlite3
import json
import re
import logging
from fastapi import FastAPI, WebSocket
import websockets
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import GigaChat
from langchain_gigachat import GigaChat
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.retrievers import EnsembleRetriever
import uvicorn

DATABASE_URL = "/app/src/main_version/AI_agent.db"

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

api_key = os.getenv("GIGACHAT_API_KEY")

folder_path_bsa = os.path.join(os.path.dirname(__file__), "docs/docs_pack_bsa")
folder_path_test = os.path.join(os.path.dirname(__file__), "docs/docs_pack_test")
folder_path_web = os.path.join(os.path.dirname(__file__), "docs/docs_pack_web")
folder_path_java = os.path.join(os.path.dirname(__file__), "docs/docs_pack_java")
folder_path_python = os.path.join(os.path.dirname(__file__), "docs/docs_pack_python")

def create_docs_from_txt(folder_path):
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ .txt –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(".txt")]

    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    docs = []

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤
    for file_path in file_paths:
        loader = TextLoader(file_path)
        docs.extend(loader.load())

    # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 500 –¥–æ 800 –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        chunk_overlap=200  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 100 –¥–æ 200 –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
    )
    split_docs = text_splitter.split_documents(docs)
    return split_docs

# –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∞–Ω–∞–ª–∏—Ç–∏–∫—É
split_docs_bsa = create_docs_from_txt(folder_path_bsa)
# –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫—É
split_docs_test = create_docs_from_txt(folder_path_test)
# –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –§—Ä–æ–Ω—Ç–µ–Ω–¥–µ—Ä—É
split_docs_web = create_docs_from_txt(folder_path_web)
# –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ Java —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É
split_docs_java = create_docs_from_txt(folder_path_java)

split_docs_python = create_docs_from_txt(folder_path_python)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ E5
model_name = "intfloat/multilingual-e5-base"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}  # E5 —Ç—Ä–µ–±—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏

def add_e5_prefix_to_query(text):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å 'query: ' –∫ —Ç–µ–∫—Å—Ç—É –¥–ª—è –º–æ–¥–µ–ª–∏ E5"""
    if not text.startswith("query: "):
        return f"query: {text}"
    return text

def add_e5_prefix_to_documents(documents):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å 'passage: ' –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –¥–ª—è –º–æ–¥–µ–ª–∏ E5"""
    processed_docs = []
    for doc in documents:
        if hasattr(doc, 'page_content'):
            # –î–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ Document
            if not doc.page_content.startswith("passage: "):
                doc.page_content = f"passage: {doc.page_content}"
            processed_docs.append(doc)
        else:
            # –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            if not doc.startswith("passage: "):
                processed_docs.append(f"passage: {doc}")
            else:
                processed_docs.append(doc)
    return processed_docs

# –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –¥–ª—è E5
class E5HuggingFaceEmbeddings(HuggingFaceEmbeddings):
    def embed_query(self, text: str) -> list[float]:
        """–≠–º–±–µ–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º 'query:'"""
        prefixed_text = add_e5_prefix_to_query(text)
        return super().embed_query(prefixed_text)
    
    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        """–≠–º–±–µ–¥–∏–Ω–≥ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º 'passage:'"""
        prefixed_texts = [f"passage: {text}" if not text.startswith("passage: ") else text for text in texts]
        return super().embed_documents(prefixed_texts)

embedding = E5HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
vector_store_bsa = FAISS.from_documents(split_docs_bsa, embedding=embedding)
embedding_retriever_bsa = vector_store_bsa.as_retriever(search_kwargs={"k": 15})

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–∞
vector_store_test = FAISS.from_documents(split_docs_test, embedding=embedding)
embedding_retriever_test = vector_store_test.as_retriever(search_kwargs={"k": 15})

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –§—Ä–æ–Ω—Ç–µ–Ω–¥ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
vector_store_web = FAISS.from_documents(split_docs_web, embedding=embedding)
embedding_retriever_web = vector_store_web.as_retriever(search_kwargs={"k": 15})

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è Java —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
vector_store_java = FAISS.from_documents(split_docs_java, embedding=embedding)
embedding_retriever_java = vector_store_java.as_retriever(search_kwargs={"k": 15})

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
vector_store_python = FAISS.from_documents(split_docs_python, embedding=embedding)
embedding_retriever_python = vector_store_python.as_retriever(search_kwargs={"k": 15})

# –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è —Ä–µ—Ç—Ä–∏–≤–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –±–∞–∑–∞–º
ensemble_retriever = EnsembleRetriever(
    retrievers=[
        embedding_retriever_bsa,
        embedding_retriever_test,
        embedding_retriever_web,
        embedding_retriever_java,
        embedding_retriever_python
    ],
    weights=[0.2, 0.2, 0.2, 0.2, 0.2]  # –†–∞–≤–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –≤—Å–µ—Ö –±–∞–∑
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ GigaChat
def create_retrieval_chain_from_folder(role, specialization, question_id, embedding_retriever, prompt_template):
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–∑ –æ—à–∏–±–æ–∫
    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ $specialization, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
    filled_prompt = prompt_template.replace('$specialization', specialization)

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
    prompt = ChatPromptTemplate.from_template(filled_prompt)

    llm = GigaChat(
        credentials=api_key,
        model='GigaChat-2-Max',
        verify_ssl_certs=False,
        profanity_check=False
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    document_chain = create_stuff_documents_chain(
        llm=llm,
        prompt=prompt
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ retrieval_chain
    retrieval_chain = create_retrieval_chain(embedding_retriever, document_chain)

    return retrieval_chain

def get_prompt_from_db(question_id):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ–º—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ ID –≤–æ–ø—Ä–æ—Å–∞"""
    conn = sqlite3.connect(DATABASE_URL)
    cursor = conn.cursor()
    
    try:
        cursor.execute("SELECT prompt_template FROM Prompts WHERE question_id = ?", (question_id,))
        result = cursor.fetchone()
        if result:
            return result[0]
        else:
            return None
    finally:
        conn.close()



def get_best_retriever_for_specialization(specialization, vector_store_preference='auto'):
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π retriever –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤–æ–ø—Ä–æ—Å–∞
    
    Args:
        specialization: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        vector_store_preference: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏–∑ –ë–î ('auto', 'by_specialization', 'analyst', 'qa', 'web', 'java', 'python', 'ensemble')
    """
    # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏–π –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â –Ω–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä—ã
    store_mapping = {
        'analyst': embedding_retriever_bsa,
        'qa': embedding_retriever_test,
        'web': embedding_retriever_web,
        'java': embedding_retriever_java,
        'python': embedding_retriever_python,
        'ensemble': ensemble_retriever
    }
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if vector_store_preference in store_mapping:
        return store_mapping[vector_store_preference]
    
    # –ï—Å–ª–∏ auto –∏–ª–∏ by_specialization, –≤—ã–±–∏—Ä–∞–µ–º –ø–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    spec_lower = specialization.lower() if specialization else ""
    
    if '–∞–Ω–∞–ª–∏—Ç–∏–∫' in spec_lower:
        return embedding_retriever_bsa
    elif '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫' in spec_lower:
        return embedding_retriever_test
    elif 'web' in spec_lower or '—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥' in spec_lower:
        return embedding_retriever_web
    elif 'java' in spec_lower:
        return embedding_retriever_java
    elif 'python' in spec_lower:
        return embedding_retriever_python
    else:
        return ensemble_retriever


def is_it_related_question(question):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å–≤—è–∑–∞–Ω –ª–∏ –≤–æ–ø—Ä–æ—Å —Å IT –∏–ª–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
    """
    question_lower = question.lower()
    
    # IT-—Ç–µ—Ä–º–∏–Ω—ã –∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è
    it_keywords = [
        '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–∫–æ–¥', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ', '–±–∞–≥', '—Ñ–∏—á–∞',
        '–∞–Ω–∞–ª–∏—Ç–∏–∫', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', 'scrum', 'agile', '–ø—Ä–æ–µ–∫—Ç', '–º–µ–Ω–µ–¥–∂–µ—Ä',
        'python', 'java', 'javascript', 'frontend', 'backend', 'api', '–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö',
        'sql', 'git', 'devops', 'ci/cd', 'docker', 'kubernetes', '–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å',
        '–∞–ª–≥–æ—Ä–∏—Ç–º', '—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞', '–ø–∞—Ç—Ç–µ—Ä–Ω', 'framework',
        '–±–∏–±–ª–∏–æ—Ç–µ–∫–∞', '–º–æ–¥—É–ª—å', '–∫–ª–∞—Å—Å', '—Ñ—É–Ω–∫—Ü–∏—è', '–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è', '–º–µ—Ç–æ–¥',
        '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', '–Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '–ø–æ–ª–∏–º–æ—Ä—Ñ–∏–∑–º', '–∏–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏—è',
        '–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏', '–º–∞—Ç—Ä–∏—Ü–∞', '–Ω–∞–≤—ã–∫–∏', '–∫–∞—Ä—å–µ—Ä–∞', '—Ä–∞–∑–≤–∏—Ç–∏–µ', '–æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å',
        '–ø—Ä–æ—Ü–µ—Å—Å', '–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è', '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', '—Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–∞', '—Å–ø—Ä–∏–Ω—Ç',
        'pm', 'po', 'product owner', 'project manager', 'team lead', 'senior', 'junior'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ IT-–∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    for keyword in it_keywords:
        if keyword in question_lower:
            return True
    
    return False

# –§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def get_best_retriever_for_role_spec(role, specialization, vector_store_preference='auto'):
    """–£—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_best_retriever_for_specialization."""
    return get_best_retriever_for_specialization(specialization, vector_store_preference)

async def generate_semantic_search_queries(question, role, specialization):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    """
    # –°–æ–∑–¥–∞–µ–º LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    llm = GigaChat(
        credentials=api_key,
        model='GigaChat-2-Max',
        verify_ssl_certs=False,
        profanity_check=False
    )
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (—É–±—Ä–∞–Ω–∞ —Ä–æ–ª—å)
    query_generation_prompt = f"""
–î–∞–Ω –≤–æ–ø—Ä–æ—Å: "{question}"
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialization if specialization else "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"}

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 5 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã:
1. –í–∫–ª—é—á–∞—Ç—å —Ç–æ—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
2. –§–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö –∏ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
3. –ë—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –∏ —Ç–æ—á–Ω—ã–º–∏ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
4. –ü–æ–∫—Ä—ã–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –ª–∏–¥–µ—Ä—Å—Ç–≤–∞
5. –£—á–∏—Ç—ã–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–º –∏–∑ 5-6 –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:
"""
    
    try:
        response = await llm.ainvoke(query_generation_prompt)
        alternative_queries = [q.strip() for q in response.content.split('\n') if q.strip()]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞
        all_queries = [question] + alternative_queries
        
        return all_queries
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
        return [question]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

async def enhanced_vector_search(question, role, specialization, embedding_retriever, top_k=8):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Ä–æ–ª—å –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    search_queries = await generate_semantic_search_queries(question, "", specialization)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    all_docs = []
    doc_scores = {}  # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ "–≥–æ–ª–æ—Å–æ–≤" –∑–∞ –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
    
    for query in search_queries:
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            docs = await embedding_retriever.ainvoke(query)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –≤–µ—Å–∞–º–∏ (–ø–µ—Ä–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤–∞–∂–Ω–µ–µ)
            weight = 1.0 / (search_queries.index(query) + 1)  # –£–±—ã–≤–∞—é—â–∏–π –≤–µ—Å
            
            for i, doc in enumerate(docs):
                doc_id = doc.metadata.get('source', '') + str(hash(doc.page_content[:100]))
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {
                        'doc': doc,
                        'score': 0,
                        'query_matches': []
                    }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –±–∞–ª–ª (–¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —Ç–æ–ø–µ –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª—å—à–µ –±–∞–ª–ª–æ–≤)
                position_weight = 1.0 / (i + 1)
                doc_scores[doc_id]['score'] += weight * position_weight
                doc_scores[doc_id]['query_matches'].append(query)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}")
            continue
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –æ–±—â–µ–º—É —Å—á–µ—Ç—É
    sorted_docs = sorted(doc_scores.values(), key=lambda x: x['score'], reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    result_docs = [item['doc'] for item in sorted_docs[:top_k]]
    
    return result_docs

async def create_enhanced_retrieval_chain(role, specialization, question_id, embedding_retriever, prompt_template):
    """
    –°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é retrieval chain —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
    """
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–∑ –æ—à–∏–±–æ–∫
    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ $specialization, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
    base_prompt = prompt_template.replace('$specialization', specialization)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ LLM
    llm = GigaChat(
        credentials=api_key,
        model='GigaChat-2-Max',
        verify_ssl_certs=False,
        profanity_check=False
    )
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–µ—Ç–æ–¥ astream
    class EnhancedRetrievalChain:
        def __init__(self, llm, base_prompt, role, specialization, embedding_retriever):
            self.llm = llm
            self.base_prompt = base_prompt
            self.specialization = specialization
            self.embedding_retriever = embedding_retriever

        async def astream(self, input_data):
            """
            –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å—Ç—Ä–∏–º–∏–Ω–≥ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–∞.
            """
            question = input_data.get('input', '')
            dialogue_context = input_data.get('dialogue_context', '[]')

            # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            docs = await enhanced_vector_search(question, None, self.specialization, self.embedding_retriever)
            
            # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            context_text = "\n\n".join([doc.page_content for doc in docs])
            
            # 3. –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω—è–µ–º {input} –∏ {context} –≤ –ø—Ä–æ–º–ø—Ç–µ
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ {input} –∏ {context} –≤ –ø—Ä–æ–º–ø—Ç–µ
            if '{input}' in self.base_prompt and '{context}' in self.base_prompt:
                # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ {input} –∏ {context}
                final_prompt = self.base_prompt.replace('{input}', question).replace('{context}', context_text)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                if dialogue_context and dialogue_context != '[]':
                    dialogue_history_prompt_part = f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{dialogue_context}"
                    final_prompt = final_prompt + dialogue_history_prompt_part
                
                # –î–û–ë–ê–í–õ–Ø–ï–ú –ò–ù–§–û–†–ú–ê–¶–ò–Æ –û –ü–†–û–§–ò–õ–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
                user_profile_context = f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {self.specialization if self.specialization else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}"
                final_prompt = final_prompt + user_profile_context
                    
            elif '{context}' in self.base_prompt:
                # –¢–æ–ª—å–∫–æ {context} (—Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–º–ø—Ç—ã)
                filled_prompt = self.base_prompt.replace('{context}', context_text)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –∏ –≤–æ–ø—Ä–æ—Å
                dialogue_history_prompt_part = ""
                if dialogue_context and dialogue_context != '[]':
                    dialogue_history_prompt_part = f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{dialogue_context}"
                
                # –î–û–ë–ê–í–õ–Ø–ï–ú –ò–ù–§–û–†–ú–ê–¶–ò–Æ –û –ü–†–û–§–ò–õ–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
                user_profile_context = f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {self.specialization if self.specialization else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}"
                
                final_prompt = f"{filled_prompt}{dialogue_history_prompt_part}{user_profile_context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"
                
            else:
                # Fallback: —Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –±–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                dialogue_history_prompt_part = ""
                if dialogue_context and dialogue_context != '[]':
                    dialogue_history_prompt_part = f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{dialogue_context}"

                # –î–û–ë–ê–í–õ–Ø–ï–ú –ò–ù–§–û–†–ú–ê–¶–ò–Æ –û –ü–†–û–§–ò–õ–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
                user_profile_context = f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {self.specialization if self.specialization else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}"

                final_prompt = f"{self.base_prompt}{dialogue_history_prompt_part}{user_profile_context}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n{context_text}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
            # print(f"\\n--- FINAL PROMPT ---\\n{final_prompt}\\n--- END FINAL PROMPT ---\\n")
            
            # 4. –°—Ç—Ä–∏–º–∏–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
            try:
                async for chunk in self.llm.astream(final_prompt):
                    if chunk and chunk.content:
                        yield {"answer": chunk.content}
            except Exception as e:
                print(f"–û–®–ò–ë–ö–ê –≤ —Å—Ç—Ä–∏–º–∏–Ω–≥–µ LLM: {e}")
                yield {"answer": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"}

    return EnhancedRetrievalChain(llm, base_prompt, role, specialization, embedding_retriever)

async def create_enhanced_retrieval_chain_for_suggestions(role, specialization, user_question, bot_answer, embedding_retriever, prompt_template):
    """
    –°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é retrieval chain –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–ø—Ä–æ–º–ø—Ç 999)
    """
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–∑ –æ—à–∏–±–æ–∫
    # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è template.substitute()
    filled_prompt = prompt_template.replace('$specialization', specialization)
    filled_prompt = filled_prompt.replace('$user_question', user_question)
    filled_prompt = filled_prompt.replace('$bot_answer', bot_answer)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ LLM
    llm = GigaChat(
        credentials=api_key,
        model='GigaChat-2-Max',
        verify_ssl_certs=False,
        profanity_check=False
    )
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
    async def enhanced_suggestions_process(input_data):
        search_query = input_data.get('input', '')
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ (—Ä–æ–ª—å –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
        relevant_docs = await enhanced_vector_search(search_query, None, specialization, embedding_retriever)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        context = "\n\n".join([doc.page_content for doc in relevant_docs])
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        final_prompt = f"""{filled_prompt}

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{context}

–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π {specialization}."""
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
        response = await llm.ainvoke(final_prompt)
        
        return {"answer": response.content}
    
    return enhanced_suggestions_process

#mplusk1
@app.websocket("/ws_suggest")
async def websocket_suggest_endpoint(websocket: WebSocket):
    await websocket.accept()
    data = await websocket.receive_text()
    payload = json.loads(data)
    
    user_question = payload.get("user_question")
    bot_answer = payload.get("bot_answer")
    role = payload.get("role")
    specialization = payload.get("specialization")

    prompt_template = get_prompt_from_db(999)
    if not prompt_template:
        await websocket.send_text(json.dumps({"error": "Prompt not found"}))
        await websocket.close()
        return

    # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º RAG –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–ø—Ä–æ–º–ø—Ç 999)
    use_rag = True
    
    if use_rag:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RAG –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤
        embedding_retriever = get_best_retriever_for_specialization(specialization)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é retrieval chain –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–ø—Ä–æ–º–ø—Ç 999)
        retrieval_chain = await create_enhanced_retrieval_chain_for_suggestions(
            role=None,  # –†–æ–ª—å –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            specialization=specialization,
            user_question=user_question,
            bot_answer=bot_answer,
            embedding_retriever=embedding_retriever,
            prompt_template=prompt_template
        )
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            search_query = f"–í–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–µ: {user_question}. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialization}"
            
            # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é
            response = await retrieval_chain({'input': search_query})
            raw_response = response.get('answer', '')
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            cleaned_response = re.sub(r'^\s*\d+\.\s*', '', raw_response, flags=re.MULTILINE)
            questions = [q.strip() for q in cleaned_response.split('\n') if q.strip() and len(q.strip()) > 10]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 –≤–æ–ø—Ä–æ—Å–æ–≤
            questions = questions[:5]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ RAG –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            use_rag = False
    
    if not use_rag:
        # --- 2. –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç GigaChat –±–µ–∑ RAG –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ---
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        general_prompt = f"""–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ–ª–Ω–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ.

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialization if specialization else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_question}

–î–∞–π —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å, —É—á–∏—Ç—ã–≤–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if question_id == 888 and context and context != "[]":
            general_prompt += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{context}"

        llm = GigaChat(
            credentials=api_key,
            model='GigaChat-2-Max',
            verify_ssl_certs=False,
            profanity_check=False
        )
        
        try:
            response = await llm.ainvoke(general_prompt)
            
            # –£–¥–∞–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
            cleaned_response = re.sub(r'^\s*\d+\.\s*', '', response.content, flags=re.MULTILINE)
            questions = [q.strip() for q in cleaned_response.split('\n') if q.strip()]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            await websocket.send_text(json.dumps({"error": str(e)}))
            await websocket.close()
            return

    await websocket.send_text(json.dumps(questions))
    await websocket.close()
#mplusk2
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ GigaChat."""
    await websocket.accept()
    question = await websocket.receive_text()
    role = await websocket.receive_text()
    specialization = await websocket.receive_text()
    question_id = await websocket.receive_text()
    context = await websocket.receive_text()
    count = await websocket.receive_text()
    
    logger.info(f"üîå RAG-–°–ï–†–í–ò–°: –ü–æ–ª—É—á–µ–Ω WebSocket –∑–∞–ø—Ä–æ—Å - question_id: {question_id}, specialization: {specialization}, question: '{question[:100]}...'")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä vector_store (–µ—Å–ª–∏ –µ—Å—Ç—å)
    try:
        vector_store = await websocket.receive_text()
        logger.info(f"üóÇÔ∏è RAG-–°–ï–†–í–ò–°: –ü–æ–ª—É—á–µ–Ω vector_store –ø–∞—Ä–∞–º–µ—Ç—Ä: {vector_store}")
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è vector_store –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'auto'")
        vector_store = 'auto'  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    
    question_id = int(question_id)
    count = int(count)
    
    prompt_template = get_prompt_from_db(question_id)
    if not prompt_template:
        prompt_template = get_prompt_from_db(777)
    
    # –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞ retriever —Ç–µ–ø–µ—Ä—å —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä vector_store (—Ä–æ–ª—å –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    embedding_retriever = get_best_retriever_for_specialization(specialization, vector_store)

    # –°–æ–∑–¥–∞–µ–º retrieval_chain –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç
    retrieval_chain = None
    should_use_rag = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º RAG
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–ª—è —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å–≤—è–∑–∞–Ω –ª–∏ –≤–æ–ø—Ä–æ—Å —Å IT
    if question_id == 888:  # –°–≤–æ–±–æ–¥–Ω—ã–π –≤–≤–æ–¥
        if not is_it_related_question(question):
            should_use_rag = False
    
    # --- 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º RAG —Ç–æ–ª—å–∫–æ –¥–ª—è IT-–≤–æ–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ---
    if should_use_rag:
        retrieval_chain = await create_enhanced_retrieval_chain(
            role="",  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            specialization=specialization,
            question_id=question_id,
            embedding_retriever=embedding_retriever,
            prompt_template=prompt_template
        )

        # –î–ª—è —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –ø–µ—Ä–µ–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, –∏–Ω–∞—á–µ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        dialogue_ctx = context if question_id == 888 and context and context != "[]" else "[]"

        async for chunk in retrieval_chain.astream({
            "input": question,
            "dialogue_context": dialogue_ctx,
        }):
            if chunk and chunk.get("answer"):
                await websocket.send_text(chunk["answer"])
    else:
        # --- 2. –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç GigaChat –±–µ–∑ RAG –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ---
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        general_prompt = f"""–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ–ª–Ω–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ.

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialization if specialization else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}

–î–∞–π —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å, —É—á–∏—Ç—ã–≤–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if question_id == 888 and context and context != "[]":
            general_prompt += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{context}"

        llm = GigaChat(
            credentials=api_key,
            model='GigaChat-2-Max',
            verify_ssl_certs=False,
            profanity_check=False
        )
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GigaChat
            response = await llm.ainvoke(general_prompt)
            await websocket.send_text(response.content)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GigaChat: {e}")
            await websocket.send_text("–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.")

    await websocket.close()

if __name__ == "__main__":
    logger.info("–ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –Ω–∞ ws://127.0.0.1:8000/ws")
    uvicorn.run(app, host="0.0.0.0", port=8000)


